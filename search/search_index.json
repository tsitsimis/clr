{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ConstrainedLR","text":"<p>constrainedlr is a drop-in replacement of sklearn's <code>linear_model.LinearRegression</code>, <code>linear_model.RidgeRegression</code>, <code>linear_model.Elasticnet</code>, <code>linear_model.Lasso</code>, with the additional ability to add coefficient constraints</p> <p>Source Code: https://github.com/tsitsimis/constrainedlr.</p>"},{"location":"#installation","title":"Installation","text":"<p> pip install constrainedlr </p>"},{"location":"API/","title":"API","text":""},{"location":"API/#src.constrainedlr.model.ConstrainedLinearRegression","title":"<code>ConstrainedLinearRegression</code>","text":"<p>         Bases: <code>BaseEstimator</code>, <code>RegressorMixin</code></p> Source code in <code>src\\constrainedlr\\model.py</code> <pre><code>class ConstrainedLinearRegression(BaseEstimator, RegressorMixin):\n    def __init__(self, fit_intercept: bool = True, alpha: float = 0.0):\n\"\"\"\n        Least squares Linear Regression with optional constraints on its coefficients/weights.\n\n        ConstrainedLinearRegression fits a linear model with coefficients w = (w1, \u2026, wp) to minimize the residual\n        sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation,\n        while at the same time imposing constraints on the signs and values of the coefficients.\n\n        Args:\n            fit_intercept:\n                Whether to calculate the intercept for this model.\n\n            alpha:\n                Constant that multiplies the L2 penalty term, controlling regularization strength.\n                alpha must be a non-negative float i.e. in [0, inf).\n\n        Attributes:\n            coef_:\n                Weight vector of shape (n_features,).\n\n            intercept_:\n                Independent/constant term in regression model. Set to None if fit_intercept = False.\n        \"\"\"\n        self.fit_intercept = fit_intercept\n        self.coef_ = None\n        self.intercept_ = None\n        self.alpha = alpha\n\n    def fit(\n        self,\n        X: Union[np.ndarray, pd.DataFrame],\n        y: np.ndarray,\n        sample_weight: np.ndarray = None,\n        coefficients_sign_constraints: dict = {},\n        coefficients_range_constraints: dict = {},\n        intercept_sign_constraint: int = 0,\n        coefficients_sum_constraint: float = None,\n    ) -&gt; \"ConstrainedLinearRegression\":\n\"\"\"\n        Fit linear model with constraints.\n\n        Args:\n            X:\n                Training data of shape (n_samples, n_features).\n\n            y:\n                Target values of shape (n_samples,).\n\n            sample_weight:\n                Individual weights of shape (n_samples,) for each sample.\n\n            coefficients_sign_constraints:\n                Dictionary with sign constraints. Keys must be integers specifying the location of the corresponding feature\n                in the columns in the dataset. Values must take the values: -1, 0, 1 indicating negative,\n                unconstrained and positive sign respectively. Any column that is not present in the\n                dictionary will default to 0.\n\n            coefficients_range_constraints:\n                Dictionary of the form: `{column_index: {\"lower\": &lt;float&gt;, \"upper\": &lt;float&gt;}}`.\n                Eiter both or one of lower or upper bounds can be specified. If a column index is not specified,\n                the coefficient remains unconstrained. Only one of `features_sign_constraints` or `coefficients_range_constraints`\n                can be provided.\n\n            intercept_sign_constraint:\n                Indicates the sign of intercept, if present, and must take the values: -1, 0, 1.\n\n            coefficients_sum_constraint:\n                Constraints the sum of all coefficients plus intercept (if present).\n\n        Returns:\n            Fitted Estimator.\n        \"\"\"\n        X, y = check_X_y(X, y)\n        validate_coefficients_sign_constraints(coefficients_sign_constraints, X)\n        validate_coefficients_range_constraints(coefficients_range_constraints, X)\n\n        if len(coefficients_sign_constraints) &gt; 0 and len(coefficients_range_constraints) &gt; 0:\n            raise ValueError(\n                \"Only one of `features_sign_constraints` or `coefficients_range_constraints` can be provided.\"\n            )\n\n        if np.ndim(y) == 1:\n            y = y.reshape(-1, 1)\n\n        n_samples, n_features = X.shape\n\n        # Augment features to fit intercept\n        if self.fit_intercept:\n            X = np.hstack([X, np.ones(n_samples).reshape(-1, 1)])\n\n        dim = X.shape[1]\n\n        # Weight matrix\n        if sample_weight is None:\n            W = np.eye(n_samples)\n        else:\n            W = np.diag(sample_weight)\n\n        # Quadratic program\n        P = X.T.dot(W).dot(X) + self.alpha * np.eye(dim)\n        P = matrix(P)\n        q = (-y.T.dot(W).dot(X)).T\n        q = matrix(q)\n\n        G, h = None, None\n        if len(coefficients_sign_constraints) &gt; 0:\n            features_sign_constraints_full = {feature: 0 for feature in range(n_features)}\n            features_sign_constraints_full.update(coefficients_sign_constraints)\n            diag_values = list(features_sign_constraints_full.values())\n            if self.fit_intercept:\n                diag_values.append(intercept_sign_constraint)\n            G = -1.0 * np.diag(\n                diag_values\n            )  # Negate since cvxopt by convention accepts inequalities of the form Gx &lt;= h\n            G = matrix(G)\n            h = np.zeros(dim)\n            h = matrix(h)\n        elif len(coefficients_range_constraints) &gt; 0:\n            coefficients_upper_bound_constraints = {\n                k: v for k, v in coefficients_range_constraints.items() if \"upper\" in v\n            }\n            G_upper = np.zeros((len(coefficients_upper_bound_constraints), dim))\n            for i, feature in enumerate(coefficients_upper_bound_constraints.keys()):\n                G_upper[i, feature] = 1\n            h_upper = np.array([v[\"upper\"] for k, v in coefficients_upper_bound_constraints.items()])\n\n            coefficients_lower_bound_constraints = {\n                k: v for k, v in coefficients_range_constraints.items() if \"lower\" in v\n            }\n            G_lower = np.zeros((len(coefficients_lower_bound_constraints), dim))\n            for i, feature in enumerate(coefficients_lower_bound_constraints.keys()):\n                G_lower[i, feature] = -1\n            h_lower = -1.0 * np.array([v[\"lower\"] for k, v in coefficients_lower_bound_constraints.items()])\n\n            G = np.concatenate([G_upper, G_lower], axis=0).astype(\"float\")\n            G = matrix(G)\n            h = np.concatenate([h_upper, h_lower])\n            h = matrix(h)\n\n        A, b = None, None\n        if coefficients_sum_constraint:\n            A = np.ones(dim).astype(\"float\")\n            A = A.reshape(1, -1)\n            A = matrix(A)\n            b = np.array([coefficients_sum_constraint]).astype(\"float\")\n            b = matrix(b)\n\n        solvers.options[\"show_progress\"] = False\n        solver = solvers.qp(P=P, q=q, G=G, h=h, A=A, b=b)\n        weights = np.array(solver[\"x\"]).flatten()\n\n        if self.fit_intercept:\n            self.coef_ = weights[0:-1]\n            self.intercept_ = weights[-1]\n        else:\n            self.coef_ = weights\n\n        return self\n\n    def predict(self, X: Union[np.ndarray, pd.DataFrame]) -&gt; np.ndarray:\n\"\"\"\n        Predict using the linear model.\n\n        Parameters:\n            X:\n                Samples of shape (n_samples, n_features).\n\n        Returns:\n            Predicted values of shape (n_samples,).\n        \"\"\"\n        check_is_fitted(self)\n        X = check_array(X)\n\n        n_samples = X.shape[0]\n\n        # Augment features for intercept\n        if self.fit_intercept:\n            X = np.hstack([X, np.ones(n_samples).reshape(-1, 1)])\n            weights = np.concatenate([self.coef_, [self.intercept_]])\n        else:\n            weights = self.coef_\n\n        y_pred = X.dot(weights)\n        return y_pred\n</code></pre>"},{"location":"API/#src.constrainedlr.model.ConstrainedLinearRegression.__init__","title":"<code>__init__(fit_intercept=True, alpha=0.0)</code>","text":"<p>Least squares Linear Regression with optional constraints on its coefficients/weights.</p> <p>ConstrainedLinearRegression fits a linear model with coefficients w = (w1, \u2026, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation, while at the same time imposing constraints on the signs and values of the coefficients.</p> <p>Parameters:</p> Name Type Description Default <code>fit_intercept</code> <code>bool</code> <p>Whether to calculate the intercept for this model.</p> <code>True</code> <code>alpha</code> <code>float</code> <p>Constant that multiplies the L2 penalty term, controlling regularization strength. alpha must be a non-negative float i.e. in [0, inf).</p> <code>0.0</code> <p>Attributes:</p> Name Type Description <code>coef_</code> <p>Weight vector of shape (n_features,).</p> <code>intercept_</code> <p>Independent/constant term in regression model. Set to None if fit_intercept = False.</p> Source code in <code>src\\constrainedlr\\model.py</code> <pre><code>def __init__(self, fit_intercept: bool = True, alpha: float = 0.0):\n\"\"\"\n    Least squares Linear Regression with optional constraints on its coefficients/weights.\n\n    ConstrainedLinearRegression fits a linear model with coefficients w = (w1, \u2026, wp) to minimize the residual\n    sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation,\n    while at the same time imposing constraints on the signs and values of the coefficients.\n\n    Args:\n        fit_intercept:\n            Whether to calculate the intercept for this model.\n\n        alpha:\n            Constant that multiplies the L2 penalty term, controlling regularization strength.\n            alpha must be a non-negative float i.e. in [0, inf).\n\n    Attributes:\n        coef_:\n            Weight vector of shape (n_features,).\n\n        intercept_:\n            Independent/constant term in regression model. Set to None if fit_intercept = False.\n    \"\"\"\n    self.fit_intercept = fit_intercept\n    self.coef_ = None\n    self.intercept_ = None\n    self.alpha = alpha\n</code></pre>"},{"location":"API/#src.constrainedlr.model.ConstrainedLinearRegression.fit","title":"<code>fit(X, y, sample_weight=None, coefficients_sign_constraints={}, coefficients_range_constraints={}, intercept_sign_constraint=0, coefficients_sum_constraint=None)</code>","text":"<p>Fit linear model with constraints.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[np.ndarray, pd.DataFrame]</code> <p>Training data of shape (n_samples, n_features).</p> required <code>y</code> <code>np.ndarray</code> <p>Target values of shape (n_samples,).</p> required <code>sample_weight</code> <code>np.ndarray</code> <p>Individual weights of shape (n_samples,) for each sample.</p> <code>None</code> <code>coefficients_sign_constraints</code> <code>dict</code> <p>Dictionary with sign constraints. Keys must be integers specifying the location of the corresponding feature in the columns in the dataset. Values must take the values: -1, 0, 1 indicating negative, unconstrained and positive sign respectively. Any column that is not present in the dictionary will default to 0.</p> <code>{}</code> <code>coefficients_range_constraints</code> <code>dict</code> <p>Dictionary of the form: <code>{column_index: {\"lower\": &lt;float&gt;, \"upper\": &lt;float&gt;}}</code>. Eiter both or one of lower or upper bounds can be specified. If a column index is not specified, the coefficient remains unconstrained. Only one of <code>features_sign_constraints</code> or <code>coefficients_range_constraints</code> can be provided.</p> <code>{}</code> <code>intercept_sign_constraint</code> <code>int</code> <p>Indicates the sign of intercept, if present, and must take the values: -1, 0, 1.</p> <code>0</code> <code>coefficients_sum_constraint</code> <code>float</code> <p>Constraints the sum of all coefficients plus intercept (if present).</p> <code>None</code> <p>Returns:</p> Type Description <code>ConstrainedLinearRegression</code> <p>Fitted Estimator.</p> Source code in <code>src\\constrainedlr\\model.py</code> <pre><code>def fit(\n    self,\n    X: Union[np.ndarray, pd.DataFrame],\n    y: np.ndarray,\n    sample_weight: np.ndarray = None,\n    coefficients_sign_constraints: dict = {},\n    coefficients_range_constraints: dict = {},\n    intercept_sign_constraint: int = 0,\n    coefficients_sum_constraint: float = None,\n) -&gt; \"ConstrainedLinearRegression\":\n\"\"\"\n    Fit linear model with constraints.\n\n    Args:\n        X:\n            Training data of shape (n_samples, n_features).\n\n        y:\n            Target values of shape (n_samples,).\n\n        sample_weight:\n            Individual weights of shape (n_samples,) for each sample.\n\n        coefficients_sign_constraints:\n            Dictionary with sign constraints. Keys must be integers specifying the location of the corresponding feature\n            in the columns in the dataset. Values must take the values: -1, 0, 1 indicating negative,\n            unconstrained and positive sign respectively. Any column that is not present in the\n            dictionary will default to 0.\n\n        coefficients_range_constraints:\n            Dictionary of the form: `{column_index: {\"lower\": &lt;float&gt;, \"upper\": &lt;float&gt;}}`.\n            Eiter both or one of lower or upper bounds can be specified. If a column index is not specified,\n            the coefficient remains unconstrained. Only one of `features_sign_constraints` or `coefficients_range_constraints`\n            can be provided.\n\n        intercept_sign_constraint:\n            Indicates the sign of intercept, if present, and must take the values: -1, 0, 1.\n\n        coefficients_sum_constraint:\n            Constraints the sum of all coefficients plus intercept (if present).\n\n    Returns:\n        Fitted Estimator.\n    \"\"\"\n    X, y = check_X_y(X, y)\n    validate_coefficients_sign_constraints(coefficients_sign_constraints, X)\n    validate_coefficients_range_constraints(coefficients_range_constraints, X)\n\n    if len(coefficients_sign_constraints) &gt; 0 and len(coefficients_range_constraints) &gt; 0:\n        raise ValueError(\n            \"Only one of `features_sign_constraints` or `coefficients_range_constraints` can be provided.\"\n        )\n\n    if np.ndim(y) == 1:\n        y = y.reshape(-1, 1)\n\n    n_samples, n_features = X.shape\n\n    # Augment features to fit intercept\n    if self.fit_intercept:\n        X = np.hstack([X, np.ones(n_samples).reshape(-1, 1)])\n\n    dim = X.shape[1]\n\n    # Weight matrix\n    if sample_weight is None:\n        W = np.eye(n_samples)\n    else:\n        W = np.diag(sample_weight)\n\n    # Quadratic program\n    P = X.T.dot(W).dot(X) + self.alpha * np.eye(dim)\n    P = matrix(P)\n    q = (-y.T.dot(W).dot(X)).T\n    q = matrix(q)\n\n    G, h = None, None\n    if len(coefficients_sign_constraints) &gt; 0:\n        features_sign_constraints_full = {feature: 0 for feature in range(n_features)}\n        features_sign_constraints_full.update(coefficients_sign_constraints)\n        diag_values = list(features_sign_constraints_full.values())\n        if self.fit_intercept:\n            diag_values.append(intercept_sign_constraint)\n        G = -1.0 * np.diag(\n            diag_values\n        )  # Negate since cvxopt by convention accepts inequalities of the form Gx &lt;= h\n        G = matrix(G)\n        h = np.zeros(dim)\n        h = matrix(h)\n    elif len(coefficients_range_constraints) &gt; 0:\n        coefficients_upper_bound_constraints = {\n            k: v for k, v in coefficients_range_constraints.items() if \"upper\" in v\n        }\n        G_upper = np.zeros((len(coefficients_upper_bound_constraints), dim))\n        for i, feature in enumerate(coefficients_upper_bound_constraints.keys()):\n            G_upper[i, feature] = 1\n        h_upper = np.array([v[\"upper\"] for k, v in coefficients_upper_bound_constraints.items()])\n\n        coefficients_lower_bound_constraints = {\n            k: v for k, v in coefficients_range_constraints.items() if \"lower\" in v\n        }\n        G_lower = np.zeros((len(coefficients_lower_bound_constraints), dim))\n        for i, feature in enumerate(coefficients_lower_bound_constraints.keys()):\n            G_lower[i, feature] = -1\n        h_lower = -1.0 * np.array([v[\"lower\"] for k, v in coefficients_lower_bound_constraints.items()])\n\n        G = np.concatenate([G_upper, G_lower], axis=0).astype(\"float\")\n        G = matrix(G)\n        h = np.concatenate([h_upper, h_lower])\n        h = matrix(h)\n\n    A, b = None, None\n    if coefficients_sum_constraint:\n        A = np.ones(dim).astype(\"float\")\n        A = A.reshape(1, -1)\n        A = matrix(A)\n        b = np.array([coefficients_sum_constraint]).astype(\"float\")\n        b = matrix(b)\n\n    solvers.options[\"show_progress\"] = False\n    solver = solvers.qp(P=P, q=q, G=G, h=h, A=A, b=b)\n    weights = np.array(solver[\"x\"]).flatten()\n\n    if self.fit_intercept:\n        self.coef_ = weights[0:-1]\n        self.intercept_ = weights[-1]\n    else:\n        self.coef_ = weights\n\n    return self\n</code></pre>"},{"location":"API/#src.constrainedlr.model.ConstrainedLinearRegression.predict","title":"<code>predict(X)</code>","text":"<p>Predict using the linear model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[np.ndarray, pd.DataFrame]</code> <p>Samples of shape (n_samples, n_features).</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>Predicted values of shape (n_samples,).</p> Source code in <code>src\\constrainedlr\\model.py</code> <pre><code>def predict(self, X: Union[np.ndarray, pd.DataFrame]) -&gt; np.ndarray:\n\"\"\"\n    Predict using the linear model.\n\n    Parameters:\n        X:\n            Samples of shape (n_samples, n_features).\n\n    Returns:\n        Predicted values of shape (n_samples,).\n    \"\"\"\n    check_is_fitted(self)\n    X = check_array(X)\n\n    n_samples = X.shape[0]\n\n    # Augment features for intercept\n    if self.fit_intercept:\n        X = np.hstack([X, np.ones(n_samples).reshape(-1, 1)])\n        weights = np.concatenate([self.coef_, [self.intercept_]])\n    else:\n        weights = self.coef_\n\n    y_pred = X.dot(weights)\n    return y_pred\n</code></pre>"},{"location":"licence/","title":"Licence","text":"<p>MIT</p>"}]}